{"/_app":{"title":" App","data":{"":""}},"/_app":{"title":" App","data":{"":""}},"/cli/create":{"title":"gboost create","data":{"":""}},"/cli/intro":{"title":"CLI Introduction","data":{"":"Welcome to the docs for gboost."}},"/core/intro":{"title":"Core Introduction","data":{"":"Welcome to the docs for gboost-node."}},"/":{"title":"Index","data":{"":""}},"/infra/intro":{"title":"Infra Introduction","data":{"":"Welcome to the docs for gboost-infra."}},"/infra/tips":{"title":"Tips","data":{"":"Don't define all your infrastructure within class constructors, use methods to make your constructs easier to follow."}},"/learn/intro":{"title":"Introduction","data":{"":"","summary#Summary":"The purpose of this training is to bring you up to speed with Green Boost (GB), a toolkit to build full stack cloud native web apps faster on AWS. Module 1 takes you through deploying a GB web app with the GB CLI. Then, subsequent modules dive deep into various aspects of your GB App including: infrastructure, frontend, backend, tooling, and clean code architecture.","why-green-boost#Why Green Boost?":"GB was built to speed up AWS Professional Services delivery of web apps to customers. Many web apps have similar needs when it comes to setting up a repository, authentication, user management, CI/CD pipelines, etc. GB's goal is provide the undifferentiated heavy lifting in these common areas. To do this, GB provides an opinionated way to build these common web app components.","does-green-boost-fit-every-use-case#Does Green Boost Fit Every Use Case?":"GB is not for all use cases. Some customers have technology requirements that are not compatible with GB. That's ok. To achieve higher development speeds, GB makes assumptions about what technologies are used. Similar to how AWS recommends enterprise customers go all-in on AWS to leverage features higher up the stack that result in faster development instead of the“multi-cloud approach that restricts customers to build with the lowest common denominator of the cloud (containers, k8s, etc.), so GB recommends building with prescribed technologies. However, if a customer has a strong opinion on one part of the stack, then you still may be able to build with GB. For example, although GB uses React, a customer could use Angular or Vue instead but they would not be able to leverage GB's UI component library, gboost-ui.","toolkit#Toolkit":"GB is a toolkit that leverages several key technologies including: TypeScript, React, AWS Cloud Development Kit (CDK), and Node.js. GB also uses other 3rd party open source tools/libraries/frameworks to help build web apps that delight customers with their quality and speed. The benefits of using 3rd party open source tools are new features and bug fixes by the community, community support (StackOverflow Q&As), and lighter maintenance burden on the GB team. 3rd party tools also have risks being maintained by another individual/organization. It's a tradeoff the GB team tries to carefully navigate. With that said, GB is not only an ad-hoc tool. The GB CLI generates a full stack web app for you which you'll do in the first training module.","module-topics#Module Topics":"You may scan through this training and think, “Wait, what is GB actually doing?” This training intentionally doesn't dive into constructs, components, and functions exported from GB's libraries. Instead it focuses on the tools GB apps are built with so you'll have a more holistic, over-arching understanding of how to deliver a GB app. In the future, additional trainings will cover those libraries more in depth."}},"/learn/m1-deploy-gb-app":{"title":"Module 1: Deploy Green Boost Template App","data":{"":"Welcome to Module 1. In this module you will deploy a Green Boost web app starting from the Aurora PostgreSQL Template.","learn#Learn":"Read through the Overview docs.\nReview the Green Boost Project Board to see what's on the road map.","apply#Apply":"","m11---deploy-the-aurora-postgresql-template#M1.1 - Deploy the Aurora PostgreSQL Template.":"Follow prerequisites.\nRun below commands:\n\n\npnpm add -g gboost\npnpm env use --global 18\ngboost create\ncd <your-directory>\npnpm i\ncd infra\npnpm deploy:local","m12---resources--constructs#M1.2 - Resources & Constructs":"While you're waiting (~20 minutes) for your CloudFormation stacks to deploy, checkout the resources in each stack being deployed. What resources are there? Which resources map to which constructs within the infrastructure code that gboost create{:bash} generated? See infrastructure code in infra/src/app/**.","m13---visit-web-app#M1.3 - Visit Web App":"View your newly deployed web app at the CloudFront URL printed by the pnpm deploy:local{:bash} command.\nYour UI stack created an output with the CloudFront URL that will look something like: myapp5stickbui9C39A55A.CloudFrontDomainName = d1q16n5pof924c.cloudfront.net which contains the URL.","m14---monitor-dashboard#M1.4 - Monitor Dashboard":"View your CloudWatch Monitoring Dashboard in the AWS Console. Which resources are being monitored? What thresholds were set for alarms?","m15---scan-code#M1.5 - Scan Code":"Review the other folders generated by gboost create{:bash}. You'll be working more with them in the next modules."}},"/learn/m2-js-ts":{"title":"Module 2: JavaScript/TypeScript","data":{"":"Green Boost uses TypeScript (TS) on the frontend, backend, and to define your infrastructure. The better you know TS, the better you'll be able to navigate each layer of your full stack web apps.","learn#Learn":"JavaScript: read/scan the MDN JavaScript Guide\nTS is a superset of JavaScript (JS), so the better you know JS, the better you know TS.\n\n\nTypeScript: read the TypeScript Handbook\nTypeScript Playground Examples: go to the TypeScript Playground, click on the Examples tab, and read/tinker with the preset examples covering\nPrimitives\nType Primitives\nMeta-Types\nLanguage\nLanguage Extensions","apply#Apply":"You've been told that in addition to supporting an items table (which the template already has), you also need to support an albums table where a user can store their albums. To begin, you'll need to write use case functions to perform the basic create, read, update, and delete functions. These functions should be type-safe and performant. For now, you can use the JSONPlaceholder API to mock your DB calls with the fake \"https://jsonplaceholder.typicode.com/albums\" resource. See guide here.","m21---create-use-case#M2.1 - Create Use Case":"Write a core/src/modules/albums/create-album.usecase.ts file that creates an album. Albums have a userId, id, and title. Ensure the userId and id are integers and the title is no longer than 100 characters. Additionally, you must ensure the user exists before creating the album.","m22---test-function#M2.2 - Test Function":"Now test your function. Create a temporary file at core/src/modules/albums/test.ts. Import the function you created in the last step, then run pnpm tsx src/modules/albums/test.ts with your current working directory as core/. Ensure you're logging the response of the JSONPlaceholder API to ensure a \"successful\" creation (the API responds like you successfully created the resource even though it isn't actually created).","m23---debug-line-by-line#M2.3 - Debug Line-By-Line":"Test your function with an invalid input, ensure the function throws an error with line-by-line debugging. To do this, set a breakpoint on the line you want to begin line-by-line debugging with and then run your pnpm tsx ... command within VS Code's JavaScript Debug Terminal.","m24---other-use-cases#M2.4 - Other Use Cases":"Create functions in a similar manner that read, update, and delete albums and then test them. Don't worry about organizing your code in a clean code architecture format like core/src/modules/item/**, we'll refactor this code in module 7.","m25---bulk-import#M2.5 - Bulk Import":"Now you've been tasked to create a use case function that bulk imports or creates albums. This function will accept an array of objects. The JSONPlaceholder API doesn't have a bulk create API, so you'll need to make individual requests. Make sure this function is performant by await{:ts}ing in parallel rather than serially."}},"/learn/m3-infra":{"title":"Module 3: Infrastructure","data":{"":"To define AWS infrastructure as code, Green Boost uses the AWS Cloud Development Kit (CDK) because it allows developers to use familiar programming languages like TypeScript to define AWS infrastructure. Additionally, the AWS CDK enables easy customization, sharing, and reusing constructs or units of infrastructure.","learn#Learn":"AWS CDK\nRead through the developer guide\nDo the AWS CDK TypeScript Workshop\n\n\ncdk-nag: scan the README and AWS Solutions Rule Pack\nReview the infra/ folder scaffolded by the GB CLI","apply#Apply":"","m31---architecture-diagram#M3.1 - Architecture Diagram":"Generate an architecture diagram of your web app with cdk-dia\nInstall Graphviz with instructions here.\nWithin the infra/ folder run pnpm cdk-dia{:bash}\nCheckout your diagram.png!","m32---deploy-the-cdk-pipeline#M3.2 - Deploy the CDK Pipeline":"You've already deployed locally your web app which is ideal for development, but for test and prod environments you'll want deployment to be automated via a Continuous Integration/Continuous Deployment (CDI/CD) Pipeline triggered by a commit to a repository. We'll use CodeCommit but keep in mind you can also use git services.\nFirst, create a CodeCommit repository in your AWS account with the same name as your appId.\nCommit code to the repository\ngit add -A\ngit commit -m \"initial commit\"\ngit remote add origin <your-code-commit-repo-url>\ngit push --set-upstream origin main\n\nIf you don’t have a workflow setup for connecting to AWS CodeCommit, try this: update your ~/.gitconfig with the below code block to use IAM credentials to authenticate to CodeCommit. For more info see here. Note: make sure to change the region in below code block if you’re not using us-east-1.\n\n\n[credential \"https://git-codecommit.us-east-1.amazonaws.com/v1/repos\"]\nhelper = # reset helper\nhelper = !aws codecommit credential-helper $@\nuseHttpPath = true\n\nRun pnpm deploy:pipeline{:bash} within infra/ folder.\nCheckout the pipeline deployed in the CodePipeline AWS Console.\nFor now, you should only see a \"dev\" stage deployed.\n\n\nAWS has a soft limit of 5 Elastic IPs (EIPs). Each stage/environment deployed uses 2 public subnets which include a NAT Gateway. Each NAT Gateway requires an EIP. Therefore, if you attempt to deploy 3 or more stages (6 EIPs) you'll surpass the limit and the deployment will fail. You can either request an increase in your EIP quota or do multi-account deployments.","m33---cdk-deploy-options#M3.3 - cdk deploy Options":"In order to deploy the Aurora PostgreSQL web app in module 1, you ran the command: pnpm deploy:local{:bash}. This command is simply an alias for the command: cdk deploy \"**\" --require-approval never --no-rollback{:bash}. You can find the alias mapping defined in infra/package.json#scripts. When developing your web app further, you'll likely only need to deploy updates to stacks one at a time. The \"**\"{:bash} in cdk deploy \"**\"{:bash} tells the CDK CLI to deploy all stacks. To only deploy updates to one stack, you can run cdk deploy \"*/<stack-id>\" --exclusively {:bash}. Try exclusively deploying your ui stack:\ncdk deploy \"*/ui\" --exclusively\nOther stack IDs include: data, monitor, and waf. These IDs are defined in infra/src/app-stage.ts. We specify a */ before the <stack-id> because in the construct tree above each of the stacks is a Stage. Stages are helpful because they allow us to encapsulate our application's stacks and deploy them locally in infra/src/local-app.ts or via a pipeline in infra/src/pipeline/pipeline-app.ts. You can specify <stage-id>/<stack-id> where stage-id is defined in infra/src/config/config.ts but we use a * because it's more concise and we're only deploying 1 stage.Exclusively deploying stacks is faster, but what if we're only changing a lambda function or another commonly changed resource and want to quickly update it without going through CloudFormation? To do this, we can use cdk deploy{:bash}'s --hotswap option. This option attempts to update your AWS resources directly (like through AWS Lambda's UpdateFunctionCode API). These updates typically take under 10 seconds 🚀. Try this out by updating a route in your Next.js app (runs as Lambda function) within the ui/src/app folder then run:\ncdk deploy \"*/ui\" --exclusively --hotswap\nYou'll notice the open-next build{:bash} process still takes a while, but the update of the Lambda function code is much faster with --hotswap.","m34---cdk-nag#M3.4 - cdk-nag":"cdk-nag checks CDK applications for best practices using a combination of available rule packs. GB templates use the AWS Solutions by default which enforces 130+ best practices. Take a moment to scan through those rules. Now, let's see cdk-nag in action.\nChange storageEncrypted: true{:ts} to false{:ts} in infra/src/app/stateful/data-stack.ts.\nRun cdk synth \"**\" --exclusively{:bash} and you should see a build error, AwsSolutions-RDS2: The RDS instance or Aurora DB cluster does not have storage encryption enabled., because the data stack is violating the rule. This is good! cdk-nag is a mechanism for preventing security misconfiguration, an OWASP Top 10 category.\nLet's say you have a requirement that necessitates having unencrypted DB storage. You can suppress a rule through several different methods documented here. In order to suppress AwsSolutions-RDS2 add the following code below the instantiation of DbIamCluster\n\n\nNagSuppressions.addResourceSuppressions(\ncluster.node.findChild(\"Resource\"),\n[\n{\nid: \"AwsSolutions-RDS2\",\nreason:\n\"Customer requirement necessitates having unencrypted DB storage\",\n},\n],\n);\n\nNow run cdk synth \"**\"{:bash} again and your CDK app should successfully synthesize. You can view all suppressed rules in infra/cdk.out/assembly-<appId>-<stageName>/AwsSolutions-<appId>-<stageName>-${stackId}-NagReport.csv. This can be sent to your security team to ensure only acceptable rule suppressions are used.","m35---multi-account-cdk-pipeline-deployment#M3.5 - Multi-account CDK Pipeline Deployment":"It's best practice to deploy stages/environments into separate AWS Accounts. In order to do this, follow the below steps.\nBootstrap the additional AWS account you'll deploy to with the command: cdk bootstrap aws://<new-aws-account-number>/<new-region> --trust <original-aws-account-number>{:bash} replacing the angle brackets with denoted values. See here for more info.\nMake sure you have the correct AWS credentials in your shell to bootstrap the account.\n\n\nUncomment the line // crossAccountKeys:true{:ts} in infra/src/pipeline/pipeline-stack.ts.\nUncomment either the test or prod stage at the bottom of infra/src/pipeline/pipeline-stack.ts.\nUpdate the static members, stageAccounts and stageRegions, of infra/src/config/config.ts with your new AWS account number and region.\nRun pnpm deploy:pipeline{:bash} again and watch progress of pipeline as it deploys to the new AWS account.\nFind the CloudFront Domain of your app deployed in your new AWS account and ensure your web app is working correctly."}},"/learn/m5-frontend":{"title":"Module 5: Frontend","data":{"":"Green Boost uses the JavaScript Library, React, the React Framework, Next.js, and the UI Component Library, Material UI.","learn#Learn":"React: read React's new and interactive learning plan.\nNext.js: read Next.js' docs focusing on Project Structure, React Essentials, Routing, Data Fetching, and Rendering.\nNotice how React Server Components enable fetching data directly in components and passing that data via props client components. This means you don't have to build backend for frontend APIs you'd traditionally need with a single page application (SPA).\nNotice how server actions enable server side mutation functions to exist within (or besides) the client components calling it. Next.js transparently handles the network requests for you.\n\n\n\n\nCo-locating client and server code is productivity boost, but also a potential security concern. Checkout the guide on Configuration to ensure server code doesn't get into client bundles.\n\nMaterial UI: scan the docs and list of components offered.","apply#Apply":"","m51---run-the-dev-server#M5.1 - Run The Dev Server":"With your DB port forwarded to your local machine as you learned in the previous module, let's run the Next.js local development server.\nWithin the ui/ folder, run pnpm dev.\nVisit http://localhost:3000 and interact with your web app locally!\nTry changing the color of the app bar by updating theme.colorSchemes.light.palette.primary.main{:ts} from colors.lagoon{:ts} to colors.carrot{:ts} in ui/src/components/theme/theme.tsx. Save the file and then watch the update happen in your browser","m52---create-the-album-table-page#M5.2 - Create The Album Table Page":"Continuing with our album feature request from the previous module, let's create an album table page so that users can list their albums.\nLet's start by adding the server component: ui/src/app/albums/page.tsx.\nYou can follow the example from ui/src/app/items/page.tsx.\nMake sure to call listAlbumsUseCase which you refactored in the last module\n\n\nNow create the client component: ui/src/app/albums/AlbumsTable.tsx.\nFollow the example from ui/src/app/items/ItemsTable.tsx excluding any code related to filtering and sorting.\n\n\nVisit http://localhost:3000/albums to see your table!\nNotice how Next.js automatically sets up routing for you based on the file structure.","m53---create-the-createview-album-page#M5.3 - Create The Create/View Album Page":"Add the Create and View album page so users can create and individually view albums.\nAdd ui/src/app/albums/new/page.tsx, ui/src/app/albums/new/CreateAlbum.tsx, and ui/src/app/albums/new/create-album-action.ts.\nUse ui/src/app/items/new/** to guide you.\nEnsure you're using the createAlbumUseCase function in ui/src/app/albums/new/create-album-action.ts you refactored in the last module\n\n\nVisit http://localhost:3000/albums/new and create a new album. Note, the id created\nGive users a way to access the page to create a new album by adding a toolbar to the top of the table. Add ui/src/app/albums/AlbumsToolbar.tsx and update ui/src/app/albums/AlbumsTable.tsx to reference it.\nUse ui/src/app/items/ItemsToolbar.tsx to guide you.\n\n\nAdd ui/src/app/albums/[id]/page.tsx, ui/src/app/albums/[id]/CreateItem.tsx, and ui/src/app/albums/[id]/update-album-action.ts.\nNote the special bracket syntax ([id]) is a Next.js convention for dynamic routes.\nUse ui/src/app/items/[id]/** to guide you.\nEnsure you're using the updateAlbumUseCase function in ui/src/app/albums/new/update-album-action.ts you refactored in the last module\n\n\nVisit http://localhost:3000/albums/<id> replacing <id> with the id of the album you previously created.","bonus#Bonus":"","m54---add-filtering-and-sorting-to-album-table-page#M5.4 - Add Filtering and Sorting to Album Table Page":"Congrats on enabling users to create, read, and update albums in your web app! Users have reported they want the ability to filter and sort. Add this capability\nCreate a script, core/src/db/scripts/seed-albums.ts to generate 10s of albums to test sorting and filtering on.\nUpdate ui/src/app/albums/AlbumsTable.tsx to add sorting and filtering capabilities to the frontend.\nUpdate core/src/modules/albums/list-albums.usecase.ts to accept parameters necessary for  filtering and sorting."}},"/learn/m6-tooling":{"title":"Module 6: Tooling","data":{"":"Green Boost (GB) tooling includes: PNPM, ESLint, TypeScript Compiler, NPM Audit, Prettier, and Husky. GB projects created with gboost create are setup as a monorepo.","learn#Learn":"Monorepo: scan Monorepos Explained\nFocus on what monorepos are and why you should use them. This explainer resource is from a 3rd party vendor but still includes valuable information. GB doesn’t use full blown monorepo tooling currently. Still considering whether additional complexity is worth it. Specifically, considering Turborepo for faster Lambda builds.\n\n\nPackage Manager: lightly scan the PNPM docs\nFocus on motivation and workspaces\n\n\nStatic Code Analysis: lightly scan the ESLint docs\nFocus on core concepts\n\n\nType Checking: lightly scan the tsc{:bash} (TypeScript Compiler) docs\n3rd Party Vulnerability Scanning: read docs here\nCode Formatting: lightly scan the Prettier docs\nYou'll notice GB templates have no prettier configuration as they use the default prettier settings. If desired, this can be easily customized as shown in the docs.\n\n\nPre-commit Hooks: lightly scan the Husky docs","apply#Apply":"","m61---pnpm-workspaces#M6.1 - PNPM Workspaces":"Review the pnpm-workspace.yaml file in root of GB repo. Understand how workspaces reference each other’s packages","m62---pnpm-scripts#M6.2 - PNPM Scripts":"Run pnpm lint{:bash} and pnpm typecheck{:bash} and pnpm test{:bash} in the root of the repository. Notice how PNPM is running those commands in every workspace that has those commands within their package.json#scripts","m63---static-code-analysis-with-eslint#M6.3 - Static Code Analysis with ESLint":"Intentionally create a code-smell (see all rules here) and verify ESLint is runs and shows red squiggles in your editor. If you're using VS Code, you will need to install the ES Lint Extension to see linting. Also recommend the Error Lens extension if you like seeing the error in line with your code.\nReview ESLint configuration. Add a custom ESLint rule. Understand how ESLint works with Prettier to enforce code formatting.","m64---npm-audit#M6.4 - NPM Audit":"pnpm audit{:bash} is an alias for npm audit{:bash}\nRun pnpm audit{:bash}. Any CVEs?\nIf you found any CVEs of sub-dependencies - dependencies that you didn't specify the version for. How can you update them? Checkout PNPM's overrides configuration option. Now override the offending package's version with the overrides configuration option and verify pnpm audit{:bash} succeeds.","m65---pre-commit-hooks#M6.5 - Pre-commit Hooks":"Make an update in a TypeScript file in each each top level folder. The change can be as trivial as adding a comment.\nNow stage and commit those changes.\nNotice how Husky's pre-commit hook defined in .husky/pre-commit runs invoking pnpm lint-staged{:bash} which in turn runs the .lintstagedrc.js file in each top level folder."}},"/learn/m7-clean-code":{"title":"Module 7: Clean Code Architecture","data":{"":"Green Boost repositories organize code such that it is modular, adaptable, and maintainable. The code organization techniques used draw upon ideas from Domain Driven Design, Hexagonal Architecture, and Vertical Slice Architecture.","learn#Learn":"Read Serverless Clean Architecture & Code with Domain-Driven Design Articles\nNote, these articles have enterprise use cases in mind. The GB app you created in week 1 is meant to be approachable so you won't see all of these concepts within the GB /core workspace\nRead Part 1: Intro, What, Why. Focus on hexagonal and onion architecture concepts\nOptional: read Part 2: Aggregates, Value Objects, Events\nOptional: read Part 3: DDD\nOptional: read Part 4: The Data Layer\n\n\nThe previous series sets up a lot of boilerplate code designed to help you organize an enterprise grade app with DDD in mind. But what if you're building a simpler app?\nRead Serverless Light Weight Clean Code Approach\n\n\nRead Amazon Prescriptive Guidance: Building hexagonal architectures on AWS\nRead Vertical Slice Architecture","apply#Apply":"","m71---architectures-compared#M7.1 - Architectures Compared":"Why is the onion/evolutionary architecture beneficial?\nWhat potential issues do you see if domain code (inner layer) starts depending upon adapters (outer layers)?\nWhat's the benefit of organizing code into vertical slices?\nHow does adding a new feature compare between code organized horizontally (by onion layer) or vertically (by feature)?","m72---code-architecture-of-core#M7.2 - Code Architecture of /core":"Review the code architecture of core/src/modules/item/*. Do you think it's modular, adaptable, and flexible? Why or why not?\nReview the code architecture of core/src/modules/album/*. How does it compare?","m73---refactor-album#M7.3 - Refactor Album":"Refactor core/src/modules/album/* to follow code architecture best practices.\nUse core/src/modules/item/* as a guide.","m74---db-refactor#M7.4 - DB Refactor":"Users cannot get enough of your new album feature. The load on the Aurora PostgreSQL cluster is too great.\nRefactor the persistence of your album entities to DynamoDB.\nDid isolating the code interacting with the DB in a repository file simplify refactoring to DynamoDB?\n\nThank you for completing the Green Boost Learn Modules. Congrats! 🎉"}},"/learn/resources":{"title":"Resources","data":{"":"There are tons of great articles/blogs/tutorials available on the web to help you build web apps with Green Boost's tech stack: TypeScript, AWS CDK, React, Node.js. Here is a consolidated list:","aws#AWS":"","aws-cdk#AWS CDK":"","clean-code#Clean Code":"Serverless Clean Code Architecture with Domain Driven Design\nAn Introduction To Domain Driven Design (DDD)\nAWS Prescriptive Guidance: Building hexagonal architectures on AWS\nDomain Driven Hexagon\nA Beginner’s Guide to Domain-centric Architectures (clean, hexagonal, …)\nVertical Slice Architecture","react#React":"","nextjs#Next.js":"Full Stack Airbnb Clone with Next.js 13 App Router: React, Tailwind, Prisma, MongoDB, NextAuth 2023","nodejs#Node.js":"","typescript#TypeScript":""}},"/overview/common-error-resolutions":{"title":"Common Error Resolutions","data":{"":"","cdk#CDK":"Error: ChangeSet [PipelineChange] does not exist (Service: AmazonCloudFormation; Status Code: 404; Error Code: ChangeSetNotFound; Request ID: ...)\nResolution: Start the pipeline execution again by selecting \"Release change\" button at top of AWS Console CodePipeline UI."}},"/overview/contributors/dependencies":{"title":"Dependencies","data":{"":"","dependencies-vs-peer-dependencies#Dependencies vs Peer Dependencies":"When building a React component, CDK construct, or Node.js function that depends on a 3rd party library outside of the core 3rd party dependencies (listed below), make those dependencies optional peer dependencies and do not export the component or construct from the index/root of the package. Export the component or construct from a subpath of the module via package.json#exports so that only consumers of the package who want to use that functionality have to install the 3rd party dependency. Core dependencies include libraries already included in the \"dependencies\" key of the package.json. Each component/construct should include any additional libraries that need to be installed in the docs.","core-3rd-party-dependencies#Core 3rd Party Dependencies":"","gboost-infra#gboost-infra":"aws-cdk-lib\ncdk-nag\nconstructs\ngboost-common","gboost-node#gboost-node":"gboost-common","gboost-ui#gboost-ui":"@emotion/cache\n@emotion/react\n@emotion/styled\n@mui/icons-material\n@mui/material\ngboost-common\nnext\nreact\nreact-dom","update-dependencies#Update Dependencies":"GB dependencies should be updated regularly. To update all patch and minor NPM versions, run pnpm -r up -i. This will launch an interactive CLI UI that allows you to pick which dependencies you want to updated. You can type a to update them all. For patch and minor version updated, you should be safe to do this.You'll also want to check for major package upgrades but tread cautiously as these new versions contain breaking changes that may or may not break GB. For major version upgrades run pnpm -r up -i --latest. For any major upgrades, make sure to check out the realease notes or changelog for the package on GitHub."}},"/overview/contributors/development-workflow":{"title":"Development Workflow","data":{"":"Open an issue here describing your feature or fix.\nCreate a branch using a descriptive name that references the issue like feat-123-description or fix-123-description.\nAdd feature, fix bug, refactor, etc.\nCreate changeset by running pnpm changeset in root of repo. Answer prompts, typically you'll be creating a minor change\nStage changes including changeset file (i.e. git add -A)\nCommit changes. Husky git commits should trigger lint-staged to run validating your staged files\nPush branch and open a PR into awslabs/green-boost's main branch.\nWork with Green Boost team to refactor PR and then wait for PR to be merged!","pull-requests#Pull Requests":"When creating a pull request (PR) that includes functionality that should be documented in the changelog and/or update the version of a package (most changes) be sure to create a changeset. Changesets are files that live within the .changeset folder and are created with pnpm changeset at the root of the green boost repository. You'll be asked what packages the changes were made in and what semantic version level (patch, minor, major) to apply. After you create these files via pnpm changeset, you can edit the generated markdown (within .changeset folder) however you'd like.When a PR is created, several continuous integration (CI) checks are run based on the ci.yml GitHub workflow. It should be required, but please make sure these pass before merging.","releases#Releases":"Changesets is used to create releases. A release includes a git tag and entry in the GitHub releases page of Green Boost. After merging changes into main, the changesets GitHub bot will automatically create a changeset-release/main branch and a PR titled, \"Version Packages\", for the packages that were updated into the main branch. When this PR is merged, the GitHub Workflow publish.yml releasing changes to NPM."}},"/overview/contributors/fix-audit-issues":{"title":"Fix Audit Issues","data":{"":"On each PR, pnpm audit is used to detect CVEs. The GitHub Actions Workflow will fail if any CVEs >= moderate severity are found by running the command pnpm audit --audit-level moderate. If the dependency is a direct dependency of your project, you should try to update dependencies. You can learn why a dependency is in your project (dependency hierarchy) with pnpm why <package-name>. If the dependency is a transitive dependency (dependency of dependency), you'll need to use PNPM's pnpm.overrides feature by adding to the package.json#pnpm.overrides object a key/value pair like: \"<package-name>@<vulnerable-version>\": \"<patched-version>\". Then run pnpm i to update your dependencies.Periodically, pnpm.overrides should be cleaned up as libraries overtime will update to patched version of packages.If there is no patched version of the library and you can safely ignore the CVE, you can add it to pnpm.auditConfig.ignoreCves."}},"/overview/contributors/intro":{"title":"Contributor's Introduction","data":{"":"Hello! Thank you for your interest in contributing to Green Boost. By contributing, you have the opportunity to scale your influence to AWS customers around the world!To get started contributing:\nFork the repository by clicking here\nClone your forked repository like: git clone https://github.com/bestickley/green-boost.git\nChange directory: cd green-boost\nInstall dependencies: pnpm i\nTry running linting: pnpm lint, typechecking: pnpm typecheck or tests: pnpm test."}},"/overview/contributors/resources":{"title":"Node.js","data":{"":"Building a library whether for React components, CDK Constructs, or Node.js takes skill.\nAdvanced React Component Composition Guide\nBuilding Future Facing Frontend Architectures\n\n\nTODO\n\n\nTODO"}},"/overview/contributors/testing-locally":{"title":"Testing Locally","data":{"":"To develop gboost-ui or gboost-infra or gboost-common in your Green Boost application repository (created with gboost create), run pnpm add ../path/to/gboost/packages/gboost-* replacing the path with the path to wherever the package is locally. This will change your package.json.Instructions below allow you to edit .ts files and test out your changes without having to compile to .js each time you make a change.","gboost-ui#gboost-ui":"After running pnpm add ../path/to/gboost/packages/gboost-ui in your GB app ui folder, you'll need to restart the Vite dev server.For any library used in gboost-ui and the consuming package (ui folder), you'll want to add that library to Vite's resolve.dedupe configuration parameter. See an explanation here. Here is an inexhaustive list: [\"aws-amplify\", \"@aws-amplify/ui-react\", \"graphql\", \"graphql-tag\", \"react\", \"react-dom\", \"react-icons\", \"react-router-dom\", \"@vanilla-extract/css\"]","gboost#gboost":"Install vite-node globally with pnpm add -g vite-node. Then you can run the CLI source (TS files) with: vite-node --options.deps.inline=\"@aws-sdk/util-user-agent-node\" ../path/to/green-boost/packages/gboost/src/index.ts -- <command>. You can remove --options.deps.inline=\"@aws-sdk/util-user-agent-node\" once this issue is resolved.","gboost-infra#gboost-infra":"After running pnpm add ../path/to/gboost/packages/gboost-infra in your GB app infra folder you'll have 2 instances of aws-cdk-lib and cdk-nag. One in your project and one in the green-boost repository. This causes an issue for cdk-nag because it uses instanceof comparisons on classes to conditionally check if resources adhere to requirements. See more here. To get around this, we'll use Vite's resolve.dedupe configuration feature. Steps:\nIn infra folder run: pnpm add -D vite vite-node\nAdd vite.config.ts\n\n\nimport { defineConfig } from \"vite\";\n\nexport default defineConfig({\nresolve: {\ndedupe: [\"aws-cdk-lib\", \"cdk-nag\"],\n},\n});\n\nChange cdk.json#app to \"/path/to/your/app/infra/node_modules/.bin/vite-node src/local-app.ts\"\ncdk synth \"**\". Now only 1 version of those libraries will be used when synthesizing your app.\n\nNote: you'll need to run pnpm build within green-boost/packages/gboost-infra if using constructs that rely on built code like custom resources."}},"/overview/contributors/tips":{"title":"Tips","data":{"":"","javascript#JavaScript":"Avoid export * from \"./some-file\". It makes tracking down imported functions/classes difficult."}},"/overview/faq":{"title":"FAQ","data":{"":"","how-does-green-boost-compare-to-amplify#How does Green Boost compare to Amplify?":"Opinions: Green Boost is more opinionated than Amplify.\nClients: Green Boost supports web. Amplify supports web and mobile.\nLanguages/Frameworks: Green Boost only supports TypeScript and React. Amplify supports multiple languages and frontend frameworks.\nInfrastructure: Green Boost uses the AWS CDK for infrastructure definition and deployment. Amplify uses CloudFormation templates for infrastructure definition (with second class support for CDK) and uses their own Amplify CLI for deployment.\nUI Component Library: Green Boost uses Material UI. Amplify uses Amplify UI.\nHosting: Green Boost uses CDK constructs for transparent hosting. Amplify has proprietary hosting solution.\nSLA: Green Boost is developed and maintained by AWS Professional Services consultants in between projects. Amplify is developer and maintained by a dedicated AWS Service team."}},"/overview/guides/aws-credentials":{"title":"AWS Credentials","data":{"":"","the-problem#The Problem":"The simplest way to use AWS Security Credentials (AWS_ACCESS_KEY_ID, ...) is to copy and paste them from your provider (like IAM Identity Center) into your shell. However, what happens when you need to start a new shell process (new terminal tab) and still need your AWS credentials? You'll need to copy and paste them from your provider again 🙄.","aws-cli#AWS CLI":"In order to persist credentials between shell processes, you can use the ~/.aws/credentials and ~/.aws/config files which are automatically recognized by the AWS CLI, SDKs, and CDK.\nAWS recommends using temporary credentials using IAM Roles. Try to avoid using long-lived IAM User credentials.\nYou can persist credentials exported into your terminal with the following commands:\naws configure set aws_access_key_id \"$AWS_ACCESS_KEY_ID\"\naws configure set aws_secret_access_key \"$AWS_SECRET_ACCESS_KEY\"\naws configure set aws_session_token \"$AWS_SESSION_TOKEN\"\nCheckout your ~/.aws/credentials and ~/.aws/config to confirm the credentials have been saved:\ncat ~/.aws/credentials\nThis works, but what if you're switching between multiple AWS accounts and want to save different sets of credentials? We need a way to separate and identify sets of credentials. This is what the AWS_PROFILE environment variable is for. You can append --profile \"$AWS_PROFILE\" to each of the previous aws configure set... commands with an exported AWS_PROFILE environment variable to identify sets of credentials.","alias#Alias":"To make the previous commands easier to run, you can create an alias, uac (update aws credentials), in your shell configuration file (.zschrc, ...) like below:\nalias uac='(\naws configure set aws_access_key_id \"$AWS_ACCESS_KEY_ID\" --profile \"$AWS_PROFILE\"\naws configure set aws_secret_access_key \"$AWS_SECRET_ACCESS_KEY\" --profile \"$AWS_PROFILE\"\naws configure set aws_session_token \"$AWS_SESSION_TOKEN\" --profile \"$AWS_PROFILE\"\necho \"AWS Credentials Updated ✅\"\n)'\nNow, with your AWS credentials and AWS_PROFILE in your shell process, you can simply run uac and your AWS credentials will be persisted but you'll need to ensure the AWS_PROFILE environment variable is set so that AWS tools know which persisted credentials to use. This is where direnv can help.","direnv#direnv":"direnv is an extension for your shell that loads and unloads environment variables in your current shell based on your current working directory. This means you can add a .envrc file at the root of your monorepo that looks like:\nexport AWS_PROFILE=my-profile\nThen run direnv allow{:bash} and now AWS_PROFILE will be set in any new shell process created within your monorepo. Prove this by running printenv | grep AWS{:bash}.\nYou'll notice in gboost create{:bash} templates, there are .envrc files already setup for you with commonly needed environment variables like AWS_PROFILE. We also include DB related environment variables so you easily connect to your DB locally. You're welcome to set other environment variables you commonly need within your .envrc file."}},"/overview/guides/clean-code":{"title":"Clean Code","data":{"":"","the-problem#The Problem":"There is no commonly agreed upon way to organize code for full stack cloud native web apps on AWS. This can make it challenging for greenfield projects to know where to start. Without a clear strategy for organizing code, projects can turn into a messy big ball of mud.In order to keep code architecture clean, this guide provides some recommendations for organizing your code. You do not have to follow it to build with Green Boost. However, keep in mind the less decisions you have to make as a developer, the faster you can build. Enforcing the right restrictions on your code can actually free you to focus on adding business value.\nFreedom is not the absence of restrictions but the presence of the right restrictions - Timothy Keller","file-structure#File Structure":"","core#core":"Center of your application.\nContains business logic.\nSubfolder structure inspired by the following design ideas. Learn more here.\nDomain Driven Design\nHexagonal Architecture\nVertical Slices\n\n\nPrimarily includes backend functionality.\nAdditionally includes common code shared between db, infra, and ui folders.\nTypical Request Path: User ↔ Primary Adapter ↔ Use Case ↔ Entity/Schema ↔ Repository ↔ Secondary Adapter ↔ External API","adaptersprimary#adapters/primary":"Bootstrap scripts that serve as the starting point of the program.\nConsidered primary adapters based on hexagonal architecture.\nDrive your application.\nDepend upon services.\nExamples includes Lambda handlers invoked by API Gateway EventBridge.","adapterssecondary#adapters/secondary":"Translate communication between the domain and the outside world.\nBased on hexagonal architecture, these are secondary adapters.\nExamples include a database repository, cache client, or email client.\nDon't contain business logic. Don't depend upon modules.","db#db":"DB related code\nStores migration files","modulesentity#modules/${entity}":"Entities represent a single instance of your domain object saved into the DB. See more here.\nHave UUID\nmodules/${entity}.db.ts\nDefines DB table for entity.\n\n\nmodules/${entity}.entity.ts\nClass including business logic related to this entity.\nDepends upon schema.\n\n\nmodules/${entity}/repository.ts\nTranslation layer between use case and secondary adapter.\nDepends on secondary adapter.\n\n\nmodules/${entity}/schema.ts\nValidation for entity to ensure business rules are followed.\nNo dependencies.\n\n\nmodules/${entity}/usecase.ts\nThin layer responsible for orchestrating collaboration between modules and adapters\nDepends upon entities, models,","modulesmodel#modules/${model}":"Models represents a real world object that is related to the domain space but not necessarily persisted. See more here.\nAlso known as value objects.\nDon't create anemic domain models which only consist of properties/attributes.","infra#infra":"AWS Cloud Development Kit (CDK) source code for defining stacks.","appstateful#app/stateful":"Collection of CDK Stacks that persist or store information on AWS.\nDeployed less infrequently.\nExamples include: network-stacks.ts, db-stack.ts, object-stack.ts.","appstateless#app/stateless":"Collection of CDK Stacks that do not persist or store information on AWS.\nDeployed frequently.\nExamples include: job-stack.ts, monitor-stack.ts, ui-stack.ts.","packages#packages":"Reusable modules across workspaces.\nExamples include TypeScript configuration and ESLint configuration.","ui#ui":"Web user interface code","app#app":"Define routing for Next.js filesystem based router.","components#components":"Reusable components found across routes.\nDon't add components here that are only used within a single routes.","context#context":"Application wide shared state that doesn't require prop-drilling.\nExamples include user information or preferences.","hooks#hooks":"Custom hooks which extract state from components allowing for reuse.\nUse when you find yourself copying and pasting ui code logic between components."}},"/overview/intro":{"title":"Welcome to Green Boost","data":{"":"Green Boost is a toolkit for building full stack cloud native web apps on AWS.","goals#Goals":"Boost developer productivity building greenfield web apps.\nProvide mechanisms to enforce security, infrastructure, and coding best practices.\nPropel developers into building business value faster with building blocks for common web app needs.\nHighlight open-source libraries and tools that improve developer productivity","motivation#Motivation":"Building a web app on AWS can feel daunting. There are many design decisions to make. While developing, there can be a lot of setup and boilerplate code. AWS Professional Services has experience building hundreds of web apps and we've learned some lessons along the way. We wanted to share with you these best practices while also providing an easy way to get started. That's why we built Green Boost.","tech-stack#Tech Stack":"Green Boost has opinions on what tech to use. A standard toolkit enables develoment teams to work faster together. 💪\nLanguage: TypeScript\nInfrastructure As Code: AWS Cloud Development Kit CDK\nBackend Runtime: Node.js\nFrontend Library: React\nFrontend Framework: Next.js"}},"/overview/packages":{"title":"Packages","data":{"":"Green Boost is published into 5 packages on NPM:\ngboost: Command Line Interface (CLI)\ngboost-common: Utility library to share commonly needed code between other libraries.\ngboost-infra: AWS CDK Constructs Library.\ngboost-node: Node.js backend code typically including functions run in AWS Lambda.\ngboost-ui: React UI Component Library built on Material UI and Next.js.\n\nEach package is versioned and released differently according to semantic versioning. Packages are only published as ES modules."}},"/overview/prereqs":{"title":"Prerequisites","data":{"":"In order to use Green Boost, you'll need to do the following:\nInstall Git\nInstall AWS CLI\nInstall PNPM\nInstall/activate Node.js 18\nIf you don't have a way to manage your Node.js versions, we recommend PNPM's built in pnpm env command where you can use the latest version of Node.js 18 with: pnpm env use --global 18\n\n\nSetup an AWS Account\nIf you're building a production grade web app, we recommend using a well-architected, multi-account AWS environment with Landing Zone. Learn more here.\n\n\nBootstrap AWS Account with the CDK\ncdk bootstrap aws://<account-number>/<region>\nEnsure you've bootstrapped us-east-1 and the region you're deploying to if different than us-east-1. This is required for CloudFront Lambda@Edge Functions.\n\n\nInject your AWS credentials into your terminal\nNot sure how to manage your AWS credentials? Checkout our guide here."}},"/overview/quick-start":{"title":"Quick Start","data":{"":"Follow the prerequisites.\nInstall the Green Boost CLI: pnpm add -g gboost.\nCreate a web app with: gboost create.\nFollow the prompts to select a template, directory, app id, and app title. To learn more about gboost create and the templates available, learn more here.\nChange directory into your directory: cd <your-directory>\nInstall dependencies: pnpm i.\nChange directory into the infrastructure folder: cd infra\nDeploy: pnpm deploy:local\nView your web app the CloudFront URL printed in your terminal towards the end of output from the previous command.\nClean up: pnpm destroy:local."}},"/ui/intro":{"title":"UI Introduction","data":{"":"Welcome to the docs for gboost-ui."}},"/learn/m4-backend":{"title":"Module 4: Backend","data":{"":"Green Boost (GB) uses Node.js as it's JavaScript server side runtime, Zod for schema validation, and Drizzle as an ORM and automatic migration generator.","learn#Learn":"Node.js: read docs on Getting Started, Asynchronous Work, Manipulating Files, and Command Line\nLambda Best Practices\nZod: scan docs\nDrizzle: scan Drizzle ORM docs and Drizzle Kit docs","apply#Apply":"","m41---db-port-forwarding#M4.1 - DB Port Forwarding":"The Aurora PostgreSQL GB template runs a DB instance in the AWS Cloud, but how can you connect to it when developing? There are several options, but we'll use SSM Session Manager Port Forwarding. In order to do so, follow these steps:\nYou should already have the AWS CLI installed by following the prerequisites\nInstall the Session Manager Plugin for the AWS CLI with the following commands from here\n\n\ncurl \"https://s3.amazonaws.com/session-manager-downloads/plugin/latest/mac/sessionmanager-bundle.zip\" -o \"sessionmanager-bundle.zip\"\nunzip sessionmanager-bundle.zip\nsudo ./sessionmanager-bundle/install -i /usr/local/sessionmanagerplugin -b /usr/local/bin/session-manager-plugin\nsession-manager-plugin\n\nIn order to forward the port from our DB to our local machine, we need a bastion host. This has already been created for you in the template. Next, we'll need 2 environment variables: DB_BASTION_ID and DB_ENDPOINT. All of these values are exported by the CloudFormation templates and therefore were printed to your terminal when deploying the web app so you can find the values by scanning the logs or by going to the AWS Console. Instructions to find these values in the console are below.\nDB_BASTION_ID: EC2 > Instances (running) > row with <stageName>-ssm-db-bastion Name > Instance ID (starts with i-)\nDB_ENDPOINT: RDS > DB Instances > Select the regional cluster with a DB Identifier like <appId>-<stageName>-data-... > Endpoints > Write instance endpoint (ends with rds.amazonaws.com)\n\n\nExport those environment variables in your shell or persist them in your .envrc file (learn more here)\nWithin core/ folder, run: pnpm db:connect{:bash}\nYou should now see \"Waiting for connections...\". This means a port from your DB is being forwarded through your DB bastion to your local machine!\n\n\nThe default timeout of SSM Session Manager is 20 minutes. You may find this annoying. You can increase the timeout up to 60 minutes in the AWS Console by going to Systems Manager > Session Manager > Preferences > Edit > Idle session timeout","m42---db-gui#M4.2 - DB GUI":"With port forwarding setup, you can now visualize your DB with a GUI like pgAdmin. Below are steps for setting up pgAdmin, but you're welcome to use another DB GUI of your choice.\nInstall pgAdmin.\nRight click on Servers in the Object Explorer. Then select Register > Server.\nGeneral tab:\nName: <appId>-<stageName>.\n\n\nConnection tab:\nHost name/address: 0.0.0.0\nUsername: <appId>_admin\nPassword: retrieve from Secrets Manager with steps: AWS Console > Secrets Manager > Select secret with Description: Generated by the CDK for the stack: <appId>-<stageName>-data > Secret Value Card > click Retrieve secret value button > copy Secret value of Secret key of \"password\".\nSave password?: yes\n\n\nClick save.\nThen drill into your DB Server to view tables: <appId>-<stageName> > Databases > <appId>_db > Schemas > <appId> > Tables.\nRight click on item table and then select \"View/Edit Data\" > All Rows.\nNow you can visualize your data locally as you develop.","m43---create-a-new-album-table#M4.3 - Create a New Album Table":"Next, we'll create a new table in our DB that will store albums supporting the feature we began working on in module 2.\nDefine the album table in core/src/modules/album/album.db.ts following the requirements specified in module 2. You can use core/src/modules/item/item.db.ts to help you.\nWith our table defined, how do we translate this definition into SQL code to update our DB? This is where Drizzle comes in as you learned above.\nTo generate the SQL to update our DB an albums table we'll run pnpm db:generate. But first, we need to set the environment variable DB_SECRET_ARN. You can find this value in the AWS Console on the same screen you retrieved the secret.\nWithin core/, run: pnpm db:generate.\nNow you should see a new migration file generated within core/src/db/drizzle/.\nNext, we'll execute the migration on our DB. Run: pnpm db:migrate.\nRefresh the tables in your DB GUI and now you should see the album table!","m44---refactor-crud-use-cases#M4.4 - Refactor CRUD Use Cases":"With the album DB table ready to be used, now you'll need to refactor the use case functions you created in module 2 to use the actual DB instead of the JSONPlaceholder API. Don't worry about using the clean code architecture like the item module, you can include all related code in the <action>.usecase.ts file. We'll refactor the use cases in module 7. Make sure to export your use case functions from core/src/modules/album/index.ts as we'll be using these functions in the next module.","bonus#Bonus":"","m45---create-a-daily-album-summary-notification-lambda-function#M4.5 - Create a Daily Album Summary Notification Lambda Function":"Now we've been asked to deliver daily emails to an administrator with the number of albums in the table. First, we need to create a lambda function.\nCreate the file: core/src/adapters/primary/album-summary-handler.ts with the below template:\n\n\nimport { fileURLToPath } from \"node:url\";\n\nexport const handler = () => {\nlet count = 0;\n// TODO: add code here to get count of rows in album table\nconsole.log(count);\n};\n\nif (process.argv[1] === fileURLToPath(import.meta.url)) {\nhandler();\n}\n\nThe code at the bottom of the above snippet ensures the handler is only run if invoked directly. Learn more here.\nAs you fill in the code to summarize the notifications, test it out by running pnpm tsx src/adapters/primary/album-summary-handler.ts","m46---create-job-stack#M4.6 - Create Job Stack":"Now create the infrastructure required to generate the daily album summary emails. You'll need a Lambda function and EventBridge rule.\nCreate a JobStack class at infra/src/app/stateless/job-stack.ts. Ensure it extends Stack.\nUse this pattern from Serverless Land as a starting point.\nUtilize gboost-infra's Function construct built on NodejsFunction to automate bundling the function with esbuild.\nEnsure your lambda function can access the DB by using getDbFnProps and connectFnToDb utility functions like in infra/src/app/stateless/ui-stack.ts.\nInstantiate the stack within infra/src/app-stage.ts.\nDeploy the new JobStack with cdk deploy{:bash}.\nManually trigger your rule to ensure expected output is logged.\nYou can manually trigger your rule by disabling (aws events disable-rule --name \"<rule-name>\"{:bash}) and then enabling (aws events enable-rule --name \"<rule-name>\"{:bash})","m47---setup-email-with-ses#M4.7 - Setup Email with SES":"We'll use Amazon SES to email yourself the summary email. In the future you can replace your email with the administrator's email. Follow the below steps.\nAWS Console > SES > Verified Identities.\nCreate Identity with your email address.\nVerify the identity by clicking on the email verification link sent to your email.\nNow use the AWS SDK for JS V3 to send an email with the following template. Use the \"Send email\" example here.\nUse the template below for the Message.Body.Text input.\n\n\nconst message = `Hello,\nThe album table has ${count} rows.\nThank you.\n`;\n\nDeploy the updated lambda function and then manually trigger the rule to ensure email is sent correctly.\nOptionally wait a day for the rule to automatically trigger"}},"/overview/guides/config":{"title":"Configuration","data":{"":"","the-problem#The Problem":"There are many places you could store your configuration with your full stack cloud native web apps on AWS including: static code, environment variables, Amazon S3, AWS Systems Manager Parameter Store, AWS Secrets Manager, AWS AppConfig, and more! Where you do you store your configuration? Additionally, when working with Next.js, how do we ensure server configuration doesn't get included in client bundles?","balanced-approach#Balanced Approach":"We believe using static code for most configuration and AWS SSM Parameter Store Secure Strings for most secrets is a great balance between simplicity and features. Static code configuration is simple to create, easy to dynamically utilize based on environment, version controlled, and updated on each deployment. AWS SSM Parameter Store Secure Strings is simple and inexpensive. If you have enterprise grade configuration management needs or dynamic configuration, please consider AWS AppConfig and AWS Secrets Manager.","shared-configuration#Shared Configuration":"In every source (src) directory of Green Boost templates, there is a config folder. This folder contains the static code configuration for the application. For example, look at core/src/config/shared-config.ts from the BasicUI template below:\nexport class SharedConfig {\nstatic appId = \"myapp\";\nconstructor(stageName?: string) {\nthis.stageName = stageName || StageName.Local;\n}\nget enumStageName(): StageName {\nreturn Object.values(StageName).includes(this.stageName as StageName)\n? (this.stageName as StageName)\n: StageName.Local;\n}\nget isLocal() {\nreturn this.enumStageName === StageName.Local;\n}\nget isProd() {\nreturn this.enumStageName === StageName.Prod;\n}\nstageName: string;\n}\nThis configuration class gives us key information about our application so that we can change the behavior of based on it's stage or environment. For example, in development we can only deploy a single writer instance as the load on our DB in development is low but in production we can add additional reader instances. Using code to store our configuration in a class means we can export the configuration class to other workspaces (infra, ui, etc.) and then inherit from this class to easily use the configuration in different environments.","keep-server-configuration-out-of-client-components#Keep Server Configuration out of Client Components":"The above shared configuration pattern can be used throughout our app. But what happens when begin to add configuration that we want to make sure isn't exposed on the client? For example, checkout core/src/config/server-config.ts from the CRUDPostgres template below:\nexport class ServerConfig extends SharedConfig {\nstatic get dbAdminUsername() {\nreturn `${SharedConfig.appId}_admin`;\n}\nstatic get dbIamUsername() {\nreturn `${SharedConfig.appId}_iam_user`;\n}\nstatic get dbName() {\nreturn `${SharedConfig.appId}_db`;\n}\nstatic envVarNames = {\nSTAGE_NAME: \"STAGE_NAME\",\nNEXT_PUBLIC_STAGE_NAME: \"NEXT_PUBLIC_STAGE_NAME\",\n};\nconstructor(stageName?: string) {\nsuper(stageName || StageName.Local);\n}\n}\nWe want to make sure the database configuration values are not accidentally included on the client side. To do this, we can export our server configuration from a sub-module export through core/package.json#exports called \"server\". Then in our ESLint configuration at /packages/eslint-config-next we can create a rule prevents importing from @myapp/core/server where the name of the package in core/ is @myapp/core. Then we can create a ui/src/core-server.ts like below:\nimport \"server-only\"; // prevents server code from being bundled into client code\n// eslint-disable-next-line no-restricted-imports\nexport * from \"@myapp1/core/server\";\nHere, we temporarily disable the eslint restriction to gain access to the configuration and re-export the value but we ensure to import the server-only package. This package ensures that only React Server Components can safely import this file. If a client component attempts to import the code, the build will fail. Additionally, if you try import from @myapp1/core/server within your ui folder, you'll get the (good) error: import is restricted from being used. Importing from @myapp/core/server directly could result in server code leaking into the client. Please import from '@/core-server'. 🛡️.","secret-configuration#Secret Configuration":"When you need to use secrets within your application, do not statically include secrets in your code or through static environment variables. At runtime, fetch the secrets and use them or dynamically inject them into your environment if needed. Use @aws-sdk/client-ssm with the GetParameterCommand to fetch secure strings. Don't forget to set WithDecryption: true."}}}